{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Image Classification\n"
      ],
      "metadata": {
        "id": "EfcnAVwyhJXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "BRBd5T4QhDeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Fashion-MNIST train and test CSV files, normalize pixel values, reshape them into image tensors, and build DataLoaders"
      ],
      "metadata": {
        "id": "EoSLv6n-3mGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset & basic preprocessing\n",
        "TRAIN_CSV_PATH = \"/content/fashion-mnist_train.csv\"\n",
        "TEST_CSV_PATH  = \"/content/fashion-mnist_test.csv\"\n",
        "\n",
        "# Load the training and test splits\n",
        "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
        "test_df  = pd.read_csv(TEST_CSV_PATH)\n",
        "\n",
        "def preprocess_fashion_df(df):\n",
        "    # Labels: class ids from 0 to 9\n",
        "    y = df.iloc[:, 0].values\n",
        "\n",
        "    # Pixel data, normalized to [0, 1]\n",
        "    X = df.iloc[:, 1:].values / 255.0\n",
        "\n",
        "    # Reshape to image tensors of shape N x 1 x 28 x 28\n",
        "    X = X.reshape(-1, 1, 28, 28)\n",
        "\n",
        "    X = torch.tensor(X, dtype=torch.float32)\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "    return X, y\n",
        "\n",
        "# Preprocess both train and test splits\n",
        "X_train, y_train = preprocess_fashion_df(train_df)\n",
        "X_test,  y_test  = preprocess_fashion_df(test_df)\n",
        "\n",
        "# Build DataLoaders: shuffle for training, no shuffle for test\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "QdpCUD89hagh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Loan Default Prediction"
      ],
      "metadata": {
        "id": "8lab2LKBhwMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "4I7x6fqUh1t4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "\n",
        "df = pd.read_csv(\"/content/Loan payments data.csv\")"
      ],
      "metadata": {
        "id": "odCniK_Ei9P2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct target label\n",
        "df[\"loan_status_binary\"] = (df[\"loan_status\"] != \"PAIDOFF\").astype(int)"
      ],
      "metadata": {
        "id": "eRdBAziOaOBc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle datetime fields\n",
        "df[\"effective_date\"] = pd.to_datetime(df[\"effective_date\"])\n",
        "df[\"due_date\"] = pd.to_datetime(df[\"due_date\"])"
      ],
      "metadata": {
        "id": "8H3DVmypaSEZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# safe derived feature:\n",
        "df[\"loan_duration_days\"] = (df[\"due_date\"] - df[\"effective_date\"]).dt.days"
      ],
      "metadata": {
        "id": "vk78bKtDaTt3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select SAFE features only (remove leakage)\n",
        "numeric_cols = [\"Principal\", \"terms\", \"age\", \"loan_duration_days\"]\n",
        "categorical_cols = [\"education\", \"Gender\"]\n",
        "\n",
        "X_raw = df[numeric_cols + categorical_cols]\n",
        "y = df[\"loan_status_binary\"]"
      ],
      "metadata": {
        "id": "THay_pohaVnB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot encoding for categorical vars\n",
        "X_cat = pd.get_dummies(X_raw[categorical_cols], drop_first=True)\n",
        "X_num = X_raw[numeric_cols]\n",
        "\n",
        "X_processed = pd.concat([X_num, X_cat], axis=1)"
      ],
      "metadata": {
        "id": "6KQRbx5PaXb4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_processed)"
      ],
      "metadata": {
        "id": "tS8KgtigaZji"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "WpCxU2qcabY7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val.values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "GGG8IBlvac3W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build DataLoader\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "9v72IC6naeY1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pos_weight for imbalanced classification\n",
        "pos_count = y_train.sum().item()\n",
        "neg_count = len(y_train) - pos_count\n",
        "pos_weight = torch.tensor([neg_count / pos_count])\n",
        "\n",
        "print(\"Preprocessing done. \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA33TVIgaful",
        "outputId": "4d19aa3a-4e94-4d8e-85b0-62cb3e171654"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing done. \n"
          ]
        }
      ]
    }
  ]
}